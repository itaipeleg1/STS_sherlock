import os
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from tqdm import tqdm
from scipy.spatial.distance import cosine
import torch
import torchvision
from torchvision import transforms
from PIL import Image
import argparse

# Cache directories for HF if needed (not relevant for VGG)
os.environ['HF_HOME'] = '/home/new_storage/sherlock/hf_cache'
os.environ['TRANSFORMERS_CACHE'] = '/home/new_storage/sherlock/hf_cache'
os.environ['HUGGINGFACE_HUB_CACHE'] = '/home/new_storage/sherlock/hf_cache'

def extract_frame_number(filepath):
    try:
        filename = os.path.basename(filepath)
        number_part = filename.split("_")[-1].split(".")[0]
        return int(''.join(c for c in number_part if c.isdigit()))
    except (ValueError, IndexError):
        return -1

def analyze_frames(root_dir, model, tr_ref, samples_per_seq=8,
                   seq_prefix='TR', seq_range=None,  
                   file_extension='.jpg', output_path='results.csv',
                   save_interval=50):
    
    samples_per_seq *= tr_ref
    seq_dirs = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d)) and d.startswith(seq_prefix)]
    seq_dirs.sort(key=lambda x: int(x[len(seq_prefix):]))
    
    if seq_range:
        start, end = seq_range
        seq_dirs = [d for d in seq_dirs if start <= int(d[len(seq_prefix):]) <= end]
    
    i = 0
    while i <= len(seq_dirs) - tr_ref:
        group_dirs = seq_dirs[i:i+tr_ref]
        group_nums = [int(d[len(seq_prefix):]) for d in group_dirs]
        group_label = f"{group_nums[0]:04d}_{group_nums[-1]:04d}"
        print(f"Processing group: {group_label}")

        frame_paths = []
        for seq_dir in group_dirs:
            seq_path = os.path.join(root_dir, seq_dir)
            frames = [os.path.join(seq_path, f) for f in os.listdir(seq_path) if f.endswith(file_extension)]
            frames.sort(key=extract_frame_number)
            frame_paths.extend(frames)
        
        total_frames = len(frame_paths)
        if total_frames == 0:
            print(f"No frames found for group {group_label}. Skipping.")
            i += tr_ref
            continue

        indices = [j * (total_frames - 1) // (samples_per_seq - 1) for j in range(samples_per_seq)]
        sampled_frames = [frame_paths[idx] for idx in indices]

        BATCHSIZE = 8
        embeddings = []

        for batch_start in range(0, len(sampled_frames), BATCHSIZE):
            batch_paths = sampled_frames[batch_start:batch_start + BATCHSIZE]
            images = [Image.open(path).convert("RGB") for path in batch_paths]
            images_transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                     std=[0.229, 0.224, 0.225])
            ])
            images_tensor = torch.stack([images_transform(img) for img in images]).to(device)

            with torch.no_grad():
                outputs = model(images_tensor)  # shape: (B, C, H, W)
                pooled = torch.nn.functional.adaptive_avg_pool2d(outputs, (1, 1))  # shape: (B, C, 1, 1)
                pooled = pooled.view(pooled.size(0), -1)  # shape: (B, C)
                embeddings.extend(pooled.cpu().numpy())

        avg_embedding = np.mean(np.stack(embeddings), axis=0)
        print(f"[DEBUG] Saving latent for group {group_label}, mean: {avg_embedding.mean():.4f}, std: {avg_embedding.std():.4f}")
        save_dir = "/home/new_storage/sherlock/STS_sherlock/projects data/VGG_embedding"
        os.makedirs(save_dir, exist_ok=True)
        np.save(os.path.join(save_dir, f"{group_label}_5.npy"), avg_embedding)

        i += tr_ref

def get_conv5_model():
    """Returns VGG16 truncated at conv5_3 (layer 28)."""
    vgg = torchvision.models.vgg16(pretrained=True)
    features = list(vgg.features.children())[:29]  # conv5_3 is index 28
    model = torch.nn.Sequential(*features)
    model.eval()
    return model.to(device)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='Extract VGG conv5 features')
    parser.add_argument('--TR_root', type=str, required=True, help='Root directory containing TR sequences')
    parser.add_argument('--output_path', type=str, help='Path to save results CSV (not used yet)')
    parser.add_argument('--start_seq', type=int, default=0)
    parser.add_argument('--end_seq', type=int, default=1000)
    parser.add_argument('--samples_per_seq', type=int, default=8)
    parser.add_argument('--tr_ref', type=int, default=1)
    parser.add_argument('--save_interval', type=int, default=50)
    args = parser.parse_args()

    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Using device: {device}")

    vgg_conv5 = get_conv5_model()

    analyze_frames(
        root_dir=args.TR_root,
        model=vgg_conv5,
        tr_ref=args.tr_ref,
        seq_range=(args.start_seq, args.end_seq),
        output_path=args.output_path,
        samples_per_seq=args.samples_per_seq,
        save_interval=args.save_interval,
    )
